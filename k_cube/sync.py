import base64
from rich.console import Console
from rich.progress import Progress
from dataclasses import dataclass
import logging
from .repository import Repository
from .client import APIClient, APIError

log = logging.getLogger(__name__)


@dataclass
class SyncResult:
    """å°è£…åŒæ­¥æ“ä½œçš„ç»“æœã€‚"""
    versions_uploaded: int = 0
    versions_downloaded: int = 0

    @property
    def has_changes(self) -> bool:
        return self.versions_uploaded > 0 or self.versions_downloaded > 0

    @property
    def direction(self) -> str:
        if self.versions_uploaded > 0 and self.versions_downloaded > 0:
            return "bidirectional"
        elif self.versions_uploaded > 0:
            return "upload"
        elif self.versions_downloaded > 0:
            return "download"
        else:
            return "none"


class Synchronizer:
    """
    è´Ÿè´£æ‰§è¡Œæœ¬åœ°ä¸è¿œç¨‹ä»“åº“ä¹‹é—´çš„åŒæ­¥æ“ä½œã€‚
    """

    def __init__(self, repo: Repository, api_client: APIClient):
        self.repo = repo
        self.client = api_client

    def sync(self) -> SyncResult:
        """
        æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„åŒå‘åŒæ­¥å‘¨æœŸï¼Œå¹¶è¿”å›è¯¦ç»†ç»“æœã€‚
        """
        log.info("ğŸ”„ å¼€å§‹åŒæ­¥...")

        local_versions = self.repo.db.get_all_version_hashes()
        sync_state = self.client.check_sync_state(
            self.repo.vault_id, local_versions)

        versions_to_upload = sync_state.get('versions_to_upload', [])
        versions_to_download = sync_state.get('versions_to_download', [])

        result = SyncResult(
            versions_uploaded=len(versions_to_upload),
            versions_downloaded=len(versions_to_download)
        )

        if versions_to_upload:
            log.info(
                f"  - [yellow]æ­£åœ¨ä¸Šä¼  {result.versions_uploaded} ä¸ªç‰ˆæœ¬...[/yellow]")
            self._push_changes(versions_to_upload)
        if versions_to_download:
            log.info(
                f"  - [green]æ­£åœ¨ä¸‹è½½ {result.versions_downloaded} ä¸ªç‰ˆæœ¬...[/green]")
            self._pull_changes(versions_to_download)

        if not result.has_changes:
            log.info("[bold green]âœ… ä½ çš„çŸ¥è¯†åº“å·²ç»æ˜¯æœ€æ–°çš„äº†ï¼[/bold green]")
        else:
            log.info("[bold green]âœ… åŒæ­¥å®Œæˆï¼[/bold green]")

        return result

    def _push_changes(self, version_hashes: list):
        """å¤„ç†ä¸Šä¼ é€»è¾‘ã€‚"""
        log.info("\n[bold yellow]â¬†ï¸ æ­£åœ¨ä¸Šä¼ æœ¬åœ°å˜æ›´...[/bold yellow]")

        # a. æ”¶é›†æ‰€æœ‰å¾…ä¸Šä¼ ç‰ˆæœ¬çš„æ•°æ®å’Œæ¶‰åŠçš„ blob
        versions_data_to_upload = []
        blobs_to_upload_hashes = set()

        for v_hash in version_hashes:
            v_data = self.repo.db.get_version_data(v_hash)
            if v_data:
                versions_data_to_upload.append(v_data)
                blobs_to_upload_hashes.update(v_data['manifest'].values())

        # b. ç­›é€‰å‡ºè¿œç¨‹ä¸å­˜åœ¨çš„ blob
        local_blob_hashes = set(self.repo.db.get_all_blob_hashes())
        # (åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œcheck_sync_state ä¹Ÿåº”è¿”å›éœ€è¦ä¸Šä¼ çš„blobå“ˆå¸Œ)
        # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬è¿™é‡Œå‡è®¾ä¸Šä¼ æ‰€æœ‰ç›¸å…³ blob

        # c. å‡†å¤‡å¹¶ä¸Šä¼  blob æ•°æ®
        blobs_payload = []
        for b_hash in blobs_to_upload_hashes:
            try:
                # æ³¨æ„: æˆ‘ä»¬éœ€è¦å‘é€åŸå§‹ï¼ˆè§£å‹åï¼‰çš„å†…å®¹ï¼Œæˆ–è€…è®©æœåŠ¡å™¨çŸ¥é“æ˜¯å‹ç¼©çš„ã€‚
                # ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å‘é€ base64 ç¼–ç çš„å‹ç¼©åå†…å®¹ã€‚
                compressed_content = self.repo._read_blob(
                    b_hash, compressed=True)
                encoded_content = base64.b64encode(
                    compressed_content).decode('ascii')
                blobs_payload.append(
                    {"hash": b_hash, "content_b64": encoded_content})
            except IOError as e:
                log.info(f"[red]é”™è¯¯ï¼šæ— æ³•è¯»å– blob {b_hash[:8]}: {e}[/red]")

        if blobs_payload:
            with Progress() as progress:
                task = progress.add_task(
                    "[cyan]ä¸Šä¼ å¯¹è±¡...", total=len(blobs_payload))
                self.client.upload_blobs(self.repo.vault_id, blobs_payload)
                progress.update(task, advance=len(blobs_payload))

        # d. ä¸Šä¼ ç‰ˆæœ¬æ•°æ®
        with Progress() as progress:
            task = progress.add_task(
                "[cyan]ä¸Šä¼ ç‰ˆæœ¬...", total=len(versions_data_to_upload))
            self.client.upload_versions(
                self.repo.vault_id, versions_data_to_upload)
            progress.update(task, advance=len(versions_data_to_upload))

    def _pull_changes(self, version_hashes: list):
        """å¤„ç†ä¸‹è½½é€»è¾‘ã€‚"""
        log.info("\n[bold green]â¬‡ï¸ æ­£åœ¨ä¸‹è½½è¿œç¨‹å˜æ›´...[/bold green]")

        # a. ä¸‹è½½ç‰ˆæœ¬å…ƒæ•°æ®
        with Progress() as progress:
            task = progress.add_task(
                "[cyan]ä¸‹è½½ç‰ˆæœ¬...", total=len(version_hashes))
            versions_data = self.client.download_versions(
                self.repo.vault_id, version_hashes)
            progress.update(task, advance=len(version_hashes))

        # b. æ‰¾å‡ºæ‰€æœ‰éœ€è¦çš„ blob å“ˆå¸Œå¹¶ä¸‹è½½
        blobs_needed = set()
        for v_data in versions_data:
            blobs_needed.update(v_data['manifest'].values())

        local_blobs = set(self.repo.db.get_all_blob_hashes())
        blobs_to_download = list(blobs_needed - local_blobs)

        if blobs_to_download:
            with Progress() as progress:
                task = progress.add_task(
                    "[cyan]ä¸‹è½½å¯¹è±¡...", total=len(blobs_to_download))
                downloaded_blobs = self.client.download_blobs(
                    self.repo.vault_id, blobs_to_download)
                progress.update(task, advance=len(blobs_to_download))

            # c. å°†ä¸‹è½½çš„ blob å†™å…¥æœ¬åœ°å¯¹è±¡åº“
            for blob in downloaded_blobs:
                self.repo._write_blob(blob['hash'], base64.b64decode(
                    blob['content_b64']), is_compressed=True)

        # d. å°†ä¸‹è½½çš„ç‰ˆæœ¬æ•°æ®å†™å…¥æ•°æ®åº“
        self.repo.db.bulk_insert_versions(versions_data)
